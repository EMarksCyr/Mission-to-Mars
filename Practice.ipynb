{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our scraping tools\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 90.0.4430\n",
      "Get LATEST driver version for 90.0.4430\n",
      "Driver [C:\\Users\\elizk\\.wdm\\drivers\\chromedriver\\win32\\90.0.4430.24\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "#set up splinter (set the executable path and initialize a chrome browser in splinter)\n",
    "executable_path = {'executable_path' : ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "#**executable_path is unpacking the dictionary we've stored the path in and headless=False means\n",
    "#that al of the browsers actions will be displayed in a chrome window \n",
    "#so we can see them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use beautiful soup to parse (take a look at the different components) the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')\n",
    "#'html.parser' is just one option to parse the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape the second heading of the site\n",
    "title = html_soup.find('h2').text\n",
    "title\n",
    "#html_doup id the object we created earlier and .find() function searches for a tag while .text extracts only the text within the html tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#In the dev-tools we found that the box of top ten tags was custom and titled \n",
    "#tags-box, this means we can just search for that term to get the content, there are \n",
    "#10 tags so we need a for loop to scrape the text from each tag encountered\n",
    "\n",
    "#create a new variable which can store the results of the search\n",
    "#in this case we are looking for the </div> elements with a class of 'tags-box'\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "#next search through the parsed results of the variable tag_box to find all <a/> elements with a 'tag' class\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "#cycle through each tag in the tags variable, strip the html code from it and print only the text of each tag\n",
    "for tag in tags:\n",
    "    word = tag.text\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start over, visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE, if you try to reuse variable names you need to restart te kernal or else \n",
    "#you'll encounter TypeError: 'ResultSet' object is not callable\n",
    "#this is because our previous practice run also used the variable name soup_quotes which results in a name conflict\n",
    "#use a for loop with five iterations (to go to pages 1-6)\n",
    "for x in range(1,6):\n",
    "    #create an HTML object, assigned to the html variable \n",
    "    html = browser.html\n",
    "    #use BeautifulSoup to parse the html object\n",
    "    quote_soup = soup (html, 'html.parser')\n",
    "    #use BeautifulSoup to find all <span /> tages with a class of 'text'\n",
    "    quotes = quote_soup.find_all('span', class_='text')\n",
    "    #use another for loop to print each quote parsed by BS\n",
    "    for quote in quotes:\n",
    "        print('page',x,'----------')\n",
    "        print(quote.text)\n",
    "    #Use splinter to click the 'Next' button when done\n",
    "    browser.links.find_by_partial_text('Next')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skill drill, Stretch your scraping skills by visiting Books to Scrape\n",
    "#(Links to an external site.) and scraping the book URL\n",
    "#list on the first page.\n",
    "\n",
    "#visit the book site\n",
    "url = 'http://books.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use beautiful soup to parse (take a look at the different components) the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_url = catalogue/a-light-in-the-attic_1000/index.html\n",
      "book_url = catalogue/tipping-the-velvet_999/index.html\n",
      "book_url = catalogue/soumission_998/index.html\n",
      "book_url = catalogue/sharp-objects_997/index.html\n",
      "book_url = catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "book_url = catalogue/the-requiem-red_995/index.html\n",
      "book_url = catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "book_url = catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "book_url = catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "book_url = catalogue/the-black-maria_991/index.html\n",
      "book_url = catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "book_url = catalogue/shakespeares-sonnets_989/index.html\n",
      "book_url = catalogue/set-me-free_988/index.html\n",
      "book_url = catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "book_url = catalogue/rip-it-up-and-start-again_986/index.html\n",
      "book_url = catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "book_url = catalogue/olio_984/index.html\n",
      "book_url = catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "book_url = catalogue/libertarianism-for-beginners_982/index.html\n",
      "book_url = catalogue/its-only-the-himalayas_981/index.html\n"
     ]
    }
   ],
   "source": [
    "#go into the section that contains all of the books\n",
    "book_box = html_soup.find('div', class_='col-sm-8 col-md-9')\n",
    "#Within book_box, grab the information within each image_container and store it \n",
    "#in a list of beautiful soup objects that represent a dom element and acts like a dictionary \n",
    "image_container_set = book_box.find_all('div', class_='image_container')\n",
    "\n",
    "#go into the set of image containers and for each image container grab the dom object a  \n",
    "for image_container in image_container_set:\n",
    "    a = image_container.find('a')\n",
    "    #print the value of the attribute href in the dom element a \n",
    "    print(\"book_url = \" + str(a['href']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
